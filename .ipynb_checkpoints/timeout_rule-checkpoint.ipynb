{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ae4ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from numpy import sqrt\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from statistics import median\n",
    "import pickle\n",
    "import csv\n",
    "import multiprocess\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2388f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list = [\n",
    "    'graylog2-server.csv',\n",
    "    'android.csv',\n",
    "    'gradle.csv',\n",
    "    'okhttp.csv',\n",
    "    'cloudify.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20222440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_values(Y_data):\n",
    "    Y_t = []\n",
    "    for e in Y_data:\n",
    "        if e == 'passed':\n",
    "            Y_t.append(1)\n",
    "        else:\n",
    "            Y_t.append(0) \n",
    "    return Y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e611bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_failures(df):\n",
    "    \n",
    "    results = df['tr_status'].tolist()\n",
    "    length = len(results)\n",
    "    verdict = ['keep']\n",
    "    prev = results[0]\n",
    "    \n",
    "    for i in range(1, length):\n",
    "        if results[i] == 0:\n",
    "            if prev == 0:\n",
    "                verdict.append('discard')\n",
    "                #print(i+1)\n",
    "            else:\n",
    "                verdict.append('keep')\n",
    "        else:\n",
    "            verdict.append('keep')\n",
    "        prev = results[i]\n",
    "    \n",
    "    df['verdict'] = verdict\n",
    "    df = df[ df['verdict'] == 'keep' ]\n",
    "    df.drop('verdict', inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57728e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_get_train_test_data(file_path, first_failures=True):\n",
    "    columns = ['tr_build_id', 'git_num_all_built_commits', 'git_diff_src_churn', 'git_diff_test_churn', 'gh_diff_files_modified', 'tr_status']\n",
    "    X = pd.read_csv(file_path, usecols = columns)\n",
    "    X['tr_status'] = output_values(X['tr_status'])\n",
    "    \n",
    "    if first_failures:\n",
    "        X = get_first_failures(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac18dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbs(project_name, ver):\n",
    "\n",
    "    project_file = \"../data/full_data/\" + project_name + '.csv'\n",
    "    \n",
    "    project =  pd_get_train_test_data(project_file)\n",
    "    pkl_file = '../data/project_data_pickles/' + project_name + '.csv_' + str(ver) + '_indexes.pkl'\n",
    "    with open(pkl_file, 'rb') as load_file:\n",
    "        train_build_ids = pickle.load(load_file)\n",
    "        test_build_ids = pickle.load(load_file)\n",
    "\n",
    "    #dataset already has first failures\n",
    "    #train_file = \"../data/train_data/\" + project_name + '_train.csv'\n",
    "    \n",
    "    \n",
    "    #X_train, Y_train = pd_get_train_test_data(train_file)\n",
    "    #X_train.drop('tr_status', inplace=True, axis=1)\n",
    "    #X_train.drop('tr_build_id', inplace=True, axis=1)\n",
    "    #X_train = X_train.reshape((int(len(X_train)), num_feature+1))\n",
    "    #print(X_train)\n",
    "    #print(Y_train)\n",
    "\n",
    "    \n",
    "\n",
    "    X_train = project [ project['tr_build_id'].isin(train_build_ids)]\n",
    "    Y_train = X_train['tr_status'].tolist()\n",
    "    \n",
    "    X_test = project [ project['tr_build_id'].isin(test_build_ids)]\n",
    "    #X_train.drop('tr_status', inplace=True, axis=1)\n",
    "    #X_train.drop('tr_build_id', inplace=True, axis=1)\n",
    "    \n",
    "    num_feature = 4\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    param_grid = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "    grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 0)\n",
    "    \n",
    "    best_n_estimators = []\n",
    "    best_max_depth = []\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_f1_sample = 0\n",
    "    best_f1_sample_result = 0\n",
    "    best_f1_estimator = 0\n",
    "    best_thresholds = []\n",
    "    \n",
    "    for i in range(100):\n",
    "        print('Bootstrapping {} for {}'.format(i, project_name))\n",
    "        \n",
    "        while True:\n",
    "            print('Here for {} {}'.format(i, project_name))\n",
    "            sample_train = resample(X_train, replace=True, n_samples=len(X_train))\n",
    "            sample_train_result = sample_train['tr_status']\n",
    "\n",
    "            build_ids = sample_train['tr_build_id'].tolist()\n",
    "            sample_test = X_train [~X_train['tr_build_id'].isin(build_ids)] \n",
    "            sample_test_result = sample_test['tr_status']\n",
    "\n",
    "            if len(sample_test_result) != 0:\n",
    "                break\n",
    "        \n",
    "        sample_train.drop('tr_status', inplace=True, axis=1)\n",
    "        sample_train.drop('tr_build_id', inplace=True, axis=1)\n",
    "        sample_test.drop('tr_status', inplace=True, axis=1)\n",
    "        sample_test.drop('tr_build_id', inplace=True, axis=1)\n",
    "        \n",
    "        print('Training {} for {}'.format(i, project_name))\n",
    "        grid_search.fit(sample_train, sample_train_result)\n",
    "        sample_pred_vals = grid_search.predict_proba(sample_test)\n",
    "\n",
    "        pred_vals = sample_pred_vals[:, 1]\n",
    "        fpr, tpr, t = roc_curve(sample_test_result, pred_vals)\n",
    "        gmeans = sqrt(tpr * (1-fpr))\n",
    "        ix = argmax(gmeans)\n",
    "        bt = t[ix]\n",
    "        best_thresholds.append(bt)\n",
    "        \n",
    "        final_pred_result = []\n",
    "        #threshold setting\n",
    "        for j in range(len(pred_vals)):\n",
    "            if pred_vals[j] > bt:\n",
    "                final_pred_result.append(1)\n",
    "            else:\n",
    "                final_pred_result.append(0)\n",
    "        \n",
    "        try:\n",
    "            f1 = f1_score(sample_test_result, final_pred_result)\n",
    "        except:\n",
    "            print('')\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_f1_sample = sample_train\n",
    "            best_f1_sample_result = sample_train_result\n",
    "            best_f1_estimator = grid_search.best_estimator_\n",
    "            print(best_f1_sample)\n",
    "            \n",
    "        best_n_estimators.append(grid_search.best_params_['n_estimators'])\n",
    "        best_max_depth.append(grid_search.best_params_['max_depth'])\n",
    "        \n",
    "    #completed with bootstrapping \n",
    "    threshold = median(best_thresholds)\n",
    "    n_estimator = median(best_n_estimators)\n",
    "    max_depth = median(best_max_depth)\n",
    "\n",
    "    #retrain to get the best model\n",
    "    forest = RandomForestClassifier(n_estimators=int(n_estimator), max_depth=int(max_depth))\n",
    "    forest.fit(best_f1_sample, best_f1_sample_result)\n",
    "\n",
    "    file_name = 'rq2_dump_data/rq2_' + project_name + '_' + str(ver) + '_best_model.pkl'\n",
    "    dump_file = open(file_name, 'wb')\n",
    "    pickle.dump(forest, dump_file)\n",
    "    pickle.dump(threshold, dump_file)\n",
    "    pickle.dump(n_estimator, dump_file)\n",
    "    pickle.dump(max_depth, dump_file)\n",
    "                \n",
    "    #grid_search.fit(X_train, Y_train)\n",
    "    #return grid_search\n",
    "    return forest, threshold, X_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
