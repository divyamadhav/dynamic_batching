{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a34c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from numpy import sqrt\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from statistics import median\n",
    "import pickle\n",
    "import csv\n",
    "import multiprocess\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from projects import project_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f888741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_total = 0\n",
    "MAX_BATCH = [1, 2, 4, 8, 16]\n",
    "algorithm = ['BATCHBISECT', 'BATCHDIVIDE4', 'BATCHSTOP4']\n",
    "confidence = list(range(2,21,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9dde98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = open('all_timeout_results.csv', 'w')\n",
    "result_headers = ['version', 'project', 'algorithm', 'batch_size', 'confidence', 'project_reqd_builds', 'project_missed_builds', 'project_saved_builds', 'project_delays', 'testall_size', 'batch_delays', 'batch_median', 'ci']\n",
    "writer = csv.writer(result_file)\n",
    "writer.writerow(result_headers)\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5d2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_values(Y_data):\n",
    "    Y_t = []\n",
    "    for e in Y_data:\n",
    "        if e == 'passed':\n",
    "            Y_t.append(1)\n",
    "        else:\n",
    "            Y_t.append(0) \n",
    "    return Y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aef410e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_failures(df):\n",
    "    \n",
    "    results = df['tr_status'].tolist()\n",
    "    length = len(results)\n",
    "    verdict = ['keep']\n",
    "    prev = results[0]\n",
    "    \n",
    "    for i in range(1, length):\n",
    "        if results[i] == 0:\n",
    "            if prev == 0:\n",
    "                verdict.append('discard')\n",
    "                #print(i+1)\n",
    "            else:\n",
    "                verdict.append('keep')\n",
    "        else:\n",
    "            verdict.append('keep')\n",
    "        prev = results[i]\n",
    "    \n",
    "    df['verdict'] = verdict\n",
    "    df = df[ df['verdict'] == 'keep' ]\n",
    "    df.drop('verdict', inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc08597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_get_train_test_data(file_path, first_failures=True):\n",
    "    columns = ['tr_build_id', 'git_num_all_built_commits', 'git_diff_src_churn', 'git_diff_test_churn', 'gh_diff_files_modified', 'tr_status']\n",
    "    X = pd.read_csv(file_path, usecols = columns)\n",
    "    X['tr_status'] = output_values(X['tr_status'])\n",
    "    \n",
    "    if first_failures:\n",
    "        X = get_first_failures(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b2ebdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbs(path, ver, train=1):\n",
    "\n",
    "    project_file = \"../data/25_1_travis_data/\" + path\n",
    "    project_name = path.split('/')[1]\n",
    "    #dataset is split using first_failures\n",
    "    project =  pd_get_train_test_data(project_file, first_failures=False)\n",
    "    \n",
    "    pkl_file = 'datasets/' + project_name + '_' + str(ver) + '.pkl'\n",
    "    with open(pkl_file, 'rb') as load_file:\n",
    "        test_build_ids = pickle.load(load_file)\n",
    "    \n",
    "\n",
    "    X_train = project [ ~project['tr_build_id'].isin(test_build_ids)]\n",
    "    Y_train = X_train['tr_status'].tolist()\n",
    "    \n",
    "    X_test = project [ project['tr_build_id'].isin(test_build_ids)]\n",
    "    \n",
    "    if train == 0:\n",
    "        return X_test\n",
    "    \n",
    "    num_feature = 4\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    param_grid = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "    grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 0)\n",
    "    \n",
    "    best_n_estimators = []\n",
    "    best_max_depth = []\n",
    "    \n",
    "    xsample = X_train.copy()\n",
    "    ysample = xsample['tr_status'].tolist()\n",
    "    xsample.drop('tr_status', inplace=True, axis=1)\n",
    "    xsample.drop('tr_build_id', inplace=True, axis=1) \n",
    "    best_f1 = 0\n",
    "    best_f1_sample = xsample\n",
    "    best_f1_sample_result = ysample\n",
    "    best_f1_estimator = 0\n",
    "    best_thresholds = []\n",
    "    \n",
    "\n",
    "    for i in range(100):\n",
    "        print('Bootstrapping {} for {}'.format(i, project_name))\n",
    "        \n",
    "        while True:\n",
    "            print('Here for {} {}'.format(i, project_name))\n",
    "            sample_train = resample(X_train, replace=True, n_samples=len(X_train))\n",
    "            sample_train_result = sample_train['tr_status']\n",
    "\n",
    "            build_ids = sample_train['tr_build_id'].tolist()\n",
    "            sample_test = X_train [~X_train['tr_build_id'].isin(build_ids)] \n",
    "            sample_test_result = sample_test['tr_status']\n",
    "\n",
    "            if len(sample_test_result) != 0:\n",
    "                break\n",
    "        \n",
    "        sample_train.drop('tr_status', inplace=True, axis=1)\n",
    "        sample_train.drop('tr_build_id', inplace=True, axis=1)\n",
    "        sample_test.drop('tr_status', inplace=True, axis=1)\n",
    "        sample_test.drop('tr_build_id', inplace=True, axis=1)\n",
    "        \n",
    "        print('Training {} for {}'.format(i, project_name))\n",
    "        grid_search.fit(sample_train, sample_train_result)\n",
    "        sample_pred_vals = grid_search.predict_proba(sample_test)\n",
    "\n",
    "        pred_vals = sample_pred_vals[:, 1]\n",
    "        fpr, tpr, t = roc_curve(sample_test_result, pred_vals)\n",
    "        gmeans = sqrt(tpr * (1-fpr))\n",
    "        ix = argmax(gmeans)\n",
    "        bt = t[ix]\n",
    "        best_thresholds.append(bt)\n",
    "        \n",
    "        final_pred_result = []\n",
    "        #threshold setting\n",
    "        for j in range(len(pred_vals)):\n",
    "            if pred_vals[j] > bt:\n",
    "                final_pred_result.append(1)\n",
    "            else:\n",
    "                final_pred_result.append(0)\n",
    "        \n",
    "        try:\n",
    "            f1 = f1_score(sample_test_result, final_pred_result)\n",
    "        except:\n",
    "            print('')\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_f1_sample = sample_train\n",
    "            best_f1_sample_result = sample_train_result\n",
    "            best_f1_estimator = grid_search.best_estimator_\n",
    "            print(best_f1_sample)\n",
    "            \n",
    "        best_n_estimators.append(grid_search.best_params_['n_estimators'])\n",
    "        best_max_depth.append(grid_search.best_params_['max_depth'])\n",
    "        \n",
    "    #completed with bootstrapping \n",
    "    threshold = median(best_thresholds)\n",
    "    n_estimator = median(best_n_estimators)\n",
    "    max_depth = median(best_max_depth)\n",
    "\n",
    "    #retrain to get the best model\n",
    "    forest = RandomForestClassifier(n_estimators=int(n_estimator), max_depth=int(max_depth))\n",
    "    forest.fit(best_f1_sample, best_f1_sample_result)\n",
    "\n",
    "    file_name = 'trained_models/' + project_name + '_' + str(ver) + '_best_model.pkl'\n",
    "    dump_file = open(file_name, 'wb')\n",
    "    pickle.dump(forest, dump_file)\n",
    "    pickle.dump(threshold, dump_file)\n",
    "    pickle.dump(n_estimator, dump_file)\n",
    "    pickle.dump(max_depth, dump_file)\n",
    "                \n",
    "    #grid_search.fit(X_train, Y_train)\n",
    "    #return grid_search\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44378b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runbatch(batch):\n",
    "\n",
    "    if 0 in batch:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dbf29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchbisect(commits):\n",
    "    global batch_total\n",
    "    \n",
    "    l = len(commits)//2\n",
    "    \n",
    "    if len(commits) == 1:\n",
    "        return 1\n",
    "    \n",
    "    if 0 in commits:\n",
    "        return 1 + batchbisect(commits[:l]) + batchbisect(commits[l:])\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a07f5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchdivide4(batch):\n",
    "    test_number =0\n",
    "    global testNumber\n",
    "\n",
    "    if (len(batch) == 12):\n",
    "        sub_batch_1 = batch[0:3]\n",
    "        sub_batch_2 = batch[3:6]\n",
    "        sub_batch_3 = batch[6:9]\n",
    "        sub_batch_4 = batch[9:12]\n",
    "        if (runbatch(sub_batch_1) == False):\n",
    "            test_number += batchstop4(sub_batch_1)\n",
    "        if (runbatch(sub_batch_2) == False):\n",
    "            test_number += batchstop4(sub_batch_2)\n",
    "        if (runbatch(sub_batch_3) == False):\n",
    "            test_number += batchstop4(sub_batch_3)\n",
    "        if (runbatch(sub_batch_4) == False):\n",
    "            test_number += batchstop4(sub_batch_4)\n",
    "        test_number += 4\n",
    "\n",
    "\n",
    "    elif (len(batch) == 11):\n",
    "        sub_batch_1 = batch[0:3]\n",
    "        sub_batch_2 = batch[3:6]\n",
    "        sub_batch_3 = batch[6:9]\n",
    "        sub_batch_4 = batch[9:11]\n",
    "        if (runbatch(sub_batch_1) == False):\n",
    "            test_number += batchstop4(sub_batch_1)\n",
    "        if (runbatch(sub_batch_2) == False):\n",
    "            test_number += batchstop4(sub_batch_2)\n",
    "        if (runbatch(sub_batch_3) == False):\n",
    "            test_number += batchstop4(sub_batch_3)\n",
    "        if (runbatch(sub_batch_4) == False):\n",
    "            test_number += batchstop4(sub_batch_4)\n",
    "        test_number += 4\n",
    "\n",
    "\n",
    "\n",
    "    elif (len(batch) == 13):\n",
    "        sub_batch_1 = batch[0:4]\n",
    "        sub_batch_2 = batch[4:7]\n",
    "        sub_batch_3 = batch[7:10]\n",
    "        sub_batch_4 = batch[10:13]\n",
    "        if (runbatch(sub_batch_1) == False):\n",
    "            test_number += batchstop4(sub_batch_1)\n",
    "        if (runbatch(sub_batch_2) == False):\n",
    "            test_number += batchstop4(sub_batch_2)\n",
    "        if (runbatch(sub_batch_3) == False):\n",
    "            test_number += batchstop4(sub_batch_3)\n",
    "        if (runbatch(sub_batch_4) == False):\n",
    "            test_number += batchstop4(sub_batch_4)\n",
    "        test_number += 4\n",
    "\n",
    "\n",
    "    elif (len(batch) == 14):\n",
    "        sub_batch_1 = batch[0:4]\n",
    "        sub_batch_2 = batch[4:7]\n",
    "        sub_batch_3 = batch[7:11]\n",
    "        sub_batch_4 = batch[11:14]\n",
    "        if (runbatch(sub_batch_1) == False):\n",
    "            test_number += batchstop4(sub_batch_1)\n",
    "        if (runbatch(sub_batch_2) == False):\n",
    "            test_number += batchstop4(sub_batch_2)\n",
    "        if (runbatch(sub_batch_3) == False):\n",
    "            test_number += batchstop4(sub_batch_3)\n",
    "        if (runbatch(sub_batch_4) == False):\n",
    "            test_number += batchstop4(sub_batch_4)\n",
    "        test_number += 4\n",
    "\n",
    "\n",
    "\n",
    "    elif (len(batch) == 15):\n",
    "        sub_batch_1 = batch[0:4]\n",
    "        sub_batch_2 = batch[4:8]\n",
    "        sub_batch_3 = batch[8:12]\n",
    "        sub_batch_4 = batch[12:15]\n",
    "        if (runbatch(sub_batch_1) == False):\n",
    "            test_number += batchstop4(sub_batch_1)\n",
    "        if (runbatch(sub_batch_2) == False):\n",
    "            test_number += batchstop4(sub_batch_2)\n",
    "        if (runbatch(sub_batch_3) == False):\n",
    "            test_number += batchstop4(sub_batch_3)\n",
    "        if (runbatch(sub_batch_4) == False):\n",
    "            test_number += batchstop4(sub_batch_4)\n",
    "        test_number += 4\n",
    "\n",
    "\n",
    "\n",
    "    elif (len(batch) == 16):\n",
    "        sub_batch_1 = batch[0:4]\n",
    "        sub_batch_2 = batch[4:8]\n",
    "        sub_batch_3 = batch[8:12]\n",
    "        sub_batch_4 = batch[12:16]\n",
    "        if (runbatch(sub_batch_1) == False):\n",
    "            test_number += batchstop4(sub_batch_1)\n",
    "        if (runbatch(sub_batch_2) == False):\n",
    "            test_number += batchstop4(sub_batch_2)\n",
    "        if (runbatch(sub_batch_3) == False):\n",
    "            test_number += batchstop4(sub_batch_3)\n",
    "        if (runbatch(sub_batch_4) == False):\n",
    "            test_number += batchstop4(sub_batch_4)\n",
    "        test_number += 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    elif (len(batch) == 17):\n",
    "        sub_batch_1 = batch[0:4]\n",
    "        sub_batch_2 = batch[4:8]\n",
    "        sub_batch_3 = batch[8:12]\n",
    "        sub_batch_4 = batch[12:17]\n",
    "        if (runbatch(sub_batch_1) == False):\n",
    "            test_number += batchstop4(sub_batch_1)\n",
    "        if (runbatch(sub_batch_2) == False):\n",
    "            test_number += batchstop4(sub_batch_2)\n",
    "        if (runbatch(sub_batch_3) == False):\n",
    "            test_number += batchstop4(sub_batch_3)\n",
    "        if (runbatch(sub_batch_4) == False):\n",
    "            test_number += batchstop4(sub_batch_4)\n",
    "        test_number += 4\n",
    "\n",
    "\n",
    "\n",
    "    elif (len(batch) == 18):\n",
    "        sub_batch_1 = batch[0:5]\n",
    "        sub_batch_2 = batch[5:9]\n",
    "        sub_batch_3 = batch[9:14]\n",
    "        sub_batch_4 = batch[14:18]\n",
    "        if (runbatch(sub_batch_1) == False):\n",
    "            test_number += batchstop4(sub_batch_1)\n",
    "        if (runbatch(sub_batch_2) == False):\n",
    "            test_number += batchstop4(sub_batch_2)\n",
    "        if (runbatch(sub_batch_3) == False):\n",
    "            test_number += batchstop4(sub_batch_3)\n",
    "        if (runbatch(sub_batch_4) == False):\n",
    "            test_number += batchstop4(sub_batch_4)\n",
    "        test_number += 4\n",
    "\n",
    "\n",
    "\n",
    "    elif (len(batch) == 19):\n",
    "        sub_batch_1 = batch[0:5]\n",
    "        sub_batch_2 = batch[5:9]\n",
    "        sub_batch_3 = batch[9:14]\n",
    "        sub_batch_4 = batch[14:19]\n",
    "        if (runbatch(sub_batch_1) == False):\n",
    "            test_number += batchstop4(sub_batch_1)\n",
    "        if (runbatch(sub_batch_2) == False):\n",
    "            test_number += batchstop4(sub_batch_2)\n",
    "        if (runbatch(sub_batch_3) == False):\n",
    "            test_number += batchstop4(sub_batch_3)\n",
    "        if (runbatch(sub_batch_4) == False):\n",
    "            test_number += batchstop4(sub_batch_4)\n",
    "        test_number += 4\n",
    "\n",
    "\n",
    "\n",
    "    elif (len(batch) <= 5):\n",
    "        test_number = test_number + len(batch)\n",
    "    else:\n",
    "\n",
    "        sub_batch_right = batch[0:(int)(len(batch) / 2)]\n",
    "        sub_batch_left = batch[(int)(len(batch) / 2):len(batch)]\n",
    "        if (runbatch(sub_batch_right) == False):\n",
    "            test_number+=batchstop4(sub_batch_right)\n",
    "        if (runbatch(sub_batch_left) == False):\n",
    "            test_number+=batchstop4(sub_batch_left)\n",
    "        test_number+=2\n",
    "\n",
    "    return test_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59a4c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchstop4(commits):\n",
    "    global batch_total\n",
    "    \n",
    "    l = len(commits)//2\n",
    "    \n",
    "    if 0 in commits:\n",
    "        \n",
    "        if len(commits) <= 4:\n",
    "            return len(commits)\n",
    "        \n",
    "        return 1 + batchstop4(commits[:l]) + batchstop4(commits[l:])\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5a76c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_rule(p, ver):\n",
    "    \n",
    "    \n",
    "    global batch_total\n",
    "    global batch_durations\n",
    "    \n",
    "    p_name = p.split('/')[1]\n",
    "    result_file = open('all_timeout_results.csv', 'a+')\n",
    "    writer = csv.writer(result_file)\n",
    "\n",
    "    \n",
    "    X_test = sbs(p, ver, train=0)\n",
    "    if len(X_test) == 0:\n",
    "        return\n",
    "    \n",
    "    dir_name = p_name[:-4].split('-', 1)[1]\n",
    "    model_file_name = '../../Models/' + dir_name + '/' + p_name + '_' + str(ver) + '_best_model.pkl'\n",
    "    model_file = open(model_file_name, 'rb')\n",
    "    predictor = pickle.load(model_file)\n",
    "    threshold = pickle.load(model_file)\n",
    "    \n",
    "    Y_test = X_test['tr_status'].tolist()\n",
    "\n",
    "    X_test.drop('tr_build_id', inplace=True, axis=1)\n",
    "    X_test.drop('tr_status', inplace=True, axis=1)\n",
    "    \n",
    "    \n",
    "    for alg in algorithm:\n",
    "        for max_batch_size in MAX_BATCH:\n",
    "                        \n",
    "            if alg == 'BATCH4':\n",
    "                if max_batch_size != 4:\n",
    "                    continue\n",
    "            \n",
    "            if alg == 'BATCHSTOP4':\n",
    "                if max_batch_size < 4:\n",
    "                    continue\n",
    "                    \n",
    "            print('Processing {} at batch size {} for {}'.format(alg, max_batch_size, p))\n",
    "\n",
    "\n",
    "            Y_result = []\n",
    "            grouped_batch = []\n",
    "            actual_group_results = []\n",
    "            group_duration = []\n",
    "            num_feature = 4 \n",
    "            length_of_test = len(Y_test)\n",
    "\n",
    "            project_reqd_builds = []\n",
    "            project_missed_builds = []\n",
    "            project_build_duration = []\n",
    "            project_saved_builds = []\n",
    "            project_delays = []\n",
    "            project_bad_builds = []\n",
    "            project_batch_delays = []\n",
    "            project_batch_medians = []\n",
    "            project_ci = []\n",
    "\n",
    "            print('Processing {}'.format(p))\n",
    "            commit = predictor.predict(X_test)\n",
    "            for c in confidence:\n",
    "                ci = [Y_test[0]]\n",
    "                batch_median = []\n",
    "                batch_delays = 0\n",
    "\n",
    "                pass_streak = Y_test[0]\n",
    "                total_builds = 0\n",
    "                missed_builds = 0\n",
    "                miss_indexes = []\n",
    "                build_indexes = []\n",
    "                delay_durations = []\n",
    "\n",
    "                if pass_streak == 0:\n",
    "                    saved_builds = 0\n",
    "                else:\n",
    "                    saved_builds = 1\n",
    "\n",
    "                index = 1\n",
    "\n",
    "                while index < len(X_test):\n",
    "                    value = commit[index]\n",
    "                    #we're setting a confidence of 'c' builds on SBS, if more than 'c' passes have been suggested in a row, we don't want to trust sbs\n",
    "                    \n",
    "                    #if predict[0][1] > threshold:\n",
    "                    #    value = 1\n",
    "                    #else:\n",
    "                    #    value = 0\n",
    "                    #print('Build {} : predict_proba={}\\tprediction={}'.format(index, predict, value))\n",
    "                    \n",
    "                    \n",
    "                    if pass_streak < c :\n",
    "                        \n",
    "                        if value == 0:\n",
    "                            while True:\n",
    "\n",
    "                                grouped_batch = list(X_test[index : index+max_batch_size])\n",
    "                                actual_group_results = list(Y_test[index : index+max_batch_size])\n",
    "\n",
    "                                if alg == 'BATCH4':\n",
    "                                    if len(actual_group_results) != max_batch_size:\n",
    "                                        fb = 0\n",
    "                                        while fb < len(actual_group_results):\n",
    "                                            #miss_indexes.append(index)\n",
    "                                            batch_delays += len(actual_group_results) - fb\n",
    "                                            batch_median.append(max_batch_size-fb-1)\n",
    "                                            ci.append(0)\n",
    "                                            fb += 1\n",
    "                                            index += 1\n",
    "                                            total_builds += 1\n",
    "                                    else:\n",
    "                                        if len(miss_indexes) > 0:\n",
    "                                            if miss_indexes[-1] < index:\n",
    "                                                for l in range(len(miss_indexes)):\n",
    "                                                    e = miss_indexes.pop()\n",
    "                                                    delay_durations.append(index - e + 1)\n",
    "\n",
    "                                        batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                        batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                        ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                        total_builds += 1\n",
    "                                        \n",
    "\n",
    "                                        if 0 in actual_group_results:\n",
    "                                            total_builds += max_batch_size\n",
    "                                            \n",
    "\n",
    "                                elif alg == 'BATCHBISECT':\n",
    "                                    if len(actual_group_results) != max_batch_size:\n",
    "                                        fb = 0\n",
    "                                        while fb < len(actual_group_results):\n",
    "                                            total_builds += 1\n",
    "                                            ci.append(0)\n",
    "                                            batch_delays += len(actual_group_results) - fb\n",
    "                                            batch_median.append(max_batch_size-fb-1)\n",
    "                                            fb += 1\n",
    "                                            index += 1\n",
    "                                    else:\n",
    "                                        if len(miss_indexes) > 0:\n",
    "                                            if miss_indexes[-1] < index:\n",
    "                                                for l in range(len(miss_indexes)):\n",
    "                                                    e = miss_indexes.pop()\n",
    "                                                    delay_durations.append(index - e + 1)\n",
    "\n",
    "                                        batch_total = batch_bisect(actual_group_results)\n",
    "                                        batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                        ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                        batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                        total_builds += batch_total\n",
    "\n",
    "                                elif alg == 'BATCHSTOP4':\n",
    "                                    if len(actual_group_results) != max_batch_size:\n",
    "                                        fb = 0\n",
    "                                        while fb < len(actual_group_results):\n",
    "                                            total_builds += 1\n",
    "                                            ci.append(0)\n",
    "                                            batch_delays += len(actual_group_results) - fb\n",
    "                                            batch_median.append(max_batch_size-fb-1)\n",
    "                                            fb += 1\n",
    "                                            index += 1\n",
    "                                    else:\n",
    "                                        if len(miss_indexes) > 0:\n",
    "                                            if miss_indexes[-1] < index:\n",
    "                                                for l in range(len(miss_indexes)):\n",
    "                                                    e = miss_indexes.pop()\n",
    "                                                    delay_durations.append(index - e + 1)\n",
    "\n",
    "                                        \n",
    "                                        batch_durations = 0\n",
    "\n",
    "                                        batch_total = batchstop4(actual_group_results)\n",
    "\n",
    "                                        batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                        ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                        batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                        total_builds += batch_total\n",
    "                                        \n",
    "                                elif alg == 'BATCHDIVIDE4':\n",
    "                                    if len(actual_group_results) != max_batch_size:\n",
    "                                        fb = 0\n",
    "                                        while fb < len(actual_group_results):\n",
    "                                            total_builds += 1\n",
    "                                            ci.append(0)\n",
    "                                            batch_delays += len(actual_group_results) - fb\n",
    "                                            batch_median.append(max_batch_size-fb-1)\n",
    "                                            fb += 1\n",
    "                                            index += 1\n",
    "                                    else:\n",
    "                                        if len(miss_indexes) > 0:\n",
    "                                            if miss_indexes[-1] < index:\n",
    "                                                for l in range(len(miss_indexes)):\n",
    "                                                    e = miss_indexes.pop()\n",
    "                                                    delay_durations.append(index - e + 1)\n",
    "\n",
    "                                        batch_total = batchdivide4(actual_group_results)\n",
    "                                        batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                        ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                        batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                        total_builds += batch_total\n",
    "\n",
    "\n",
    "                                if 0 in actual_group_results:\n",
    "                                    index += max_batch_size\n",
    "                                    grouped_batch.clear()\n",
    "                                    actual_group_results.clear()\n",
    "                                    \n",
    "                                else:\n",
    "                                    break\n",
    "                            index += max_batch_size\n",
    "                            pass_streak = 1\n",
    "                            grouped_batch.clear()\n",
    "                            actual_group_results.clear()\n",
    "                            \n",
    "                                \n",
    "                        else:\n",
    "                            pass_streak += 1\n",
    "                            ci.append(1)\n",
    "                            saved_builds += 1\n",
    "                            if Y_test[index] == 0:\n",
    "                                missed_builds += 1\n",
    "                                miss_indexes.append(index)\n",
    "\n",
    "                            #seeing only one build\n",
    "                            index += 1\n",
    "\n",
    "                    else:\n",
    "                        while True:\n",
    "\n",
    "                            grouped_batch = list(X_test[index : index+max_batch_size])\n",
    "                            actual_group_results = list(Y_test[index : index+max_batch_size])\n",
    "                            \n",
    "\n",
    "                            if alg == 'BATCH4':\n",
    "                                if len(actual_group_results) != max_batch_size:\n",
    "                                    fb = 0\n",
    "                                    while fb < len(actual_group_results):\n",
    "                                        total_builds += 1\n",
    "                                        ci.append(0)\n",
    "                                        batch_delays += len(actual_group_results) - fb\n",
    "                                        batch_median.append(max_batch_size-fb-1)\n",
    "                                        fb += 1\n",
    "                                        index += 1\n",
    "                                else:\n",
    "                                    if len(miss_indexes) > 0:\n",
    "                                        if miss_indexes[-1] < index:\n",
    "                                            for l in range(len(miss_indexes)):\n",
    "                                                e = miss_indexes.pop()\n",
    "                                                delay_durations.append(index - e + 1)\n",
    "                                    \n",
    "                                    batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                    ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                    batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                    total_builds += 1\n",
    "                                    \n",
    "\n",
    "                                    if 0 in actual_group_results:\n",
    "                                        total_builds += max_batch_size\n",
    "                                        \n",
    "\n",
    "                            elif alg == 'BATCHBISECT':\n",
    "                                if len(actual_group_results) != max_batch_size:\n",
    "                                    fb = 0\n",
    "                                    while fb < len(actual_group_results):\n",
    "                                        total_builds += 1\n",
    "                                        ci.append(0)\n",
    "                                        batch_delays += len(actual_group_results) - fb\n",
    "                                        batch_median.append(max_batch_size-fb-1)\n",
    "                                        fb += 1\n",
    "                                        index += 1\n",
    "                                else:\n",
    "\n",
    "                                    if len(miss_indexes) > 0:\n",
    "                                        if miss_indexes[-1] < index:\n",
    "                                            for l in range(len(miss_indexes)):\n",
    "                                                e = miss_indexes.pop()\n",
    "                                                delay_durations.append(index - e + 1)\n",
    "\n",
    "                                    batch_total = batch_bisect(actual_group_results)\n",
    "\n",
    "                                    batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                    batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                    \n",
    "                                    ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                    total_builds += batch_total\n",
    "\n",
    "                            elif alg == 'BATCHSTOP4':\n",
    "                                if len(actual_group_results) != max_batch_size:\n",
    "                                    fb = 0\n",
    "                                    while fb < len(actual_group_results):\n",
    "                                        total_builds += 1\n",
    "                                        ci.append(0)\n",
    "                                        batch_delays += len(actual_group_results) - fb\n",
    "                                        batch_median.append(max_batch_size-fb-1)\n",
    "                                        fb += 1\n",
    "                                        index += 1\n",
    "                                else:\n",
    "\n",
    "                                    if len(miss_indexes) > 0:\n",
    "                                        if miss_indexes[-1] < index:\n",
    "                                            for l in range(len(miss_indexes)):\n",
    "                                                e = miss_indexes.pop()\n",
    "                                                delay_durations.append(index - e + 1)\n",
    "\n",
    "                                    batch_total = batchstop4(actual_group_results)\n",
    "\n",
    "                                    batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                    batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                    ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                    total_builds += batch_total\n",
    "                            elif alg == 'BATCHDIVIDE4':\n",
    "                                if len(actual_group_results) != max_batch_size:\n",
    "                                    fb = 0\n",
    "                                    while fb < len(actual_group_results):\n",
    "                                        total_builds += 1\n",
    "                                        ci.append(0)\n",
    "                                        batch_delays += len(actual_group_results) - fb\n",
    "                                        batch_median.append(max_batch_size-fb-1)\n",
    "                                        fb += 1\n",
    "                                        index += 1\n",
    "                                else:\n",
    "\n",
    "                                    if len(miss_indexes) > 0:\n",
    "                                        if miss_indexes[-1] < index:\n",
    "                                            for l in range(len(miss_indexes)):\n",
    "                                                e = miss_indexes.pop()\n",
    "                                                delay_durations.append(index - e + 1)\n",
    "\n",
    "                                    batch_total = batchdivide4(actual_group_results)\n",
    "\n",
    "                                    batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                    batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                    ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                    total_builds += batch_total\n",
    "                                    \n",
    "                            if 0 in actual_group_results:\n",
    "                                index += max_batch_size\n",
    "                                grouped_batch.clear()\n",
    "                                actual_group_results.clear()\n",
    "                                \n",
    "                            else:\n",
    "                                break\n",
    "                        index += max_batch_size\n",
    "                        pass_streak = 1\n",
    "                        grouped_batch.clear()\n",
    "                        actual_group_results.clear()\n",
    "                        \n",
    "                mi = 0\n",
    "                while len(miss_indexes) > 0:\n",
    "                        m_index = miss_indexes.pop()\n",
    "                        delay_durations.append(length_of_test - m_index + 1)\n",
    "\n",
    "                project_reqd_builds.append(total_builds)\n",
    "                project_missed_builds.append(missed_builds)\n",
    "                project_saved_builds.append(saved_builds)\n",
    "                project_delays.append(delay_durations)\n",
    "                project_batch_delays.append(batch_delays)\n",
    "                project_batch_medians.append(batch_median)\n",
    "                project_ci.append(ci)\n",
    "                \n",
    "                if len(ci) != len(commit):\n",
    "                    print(len(ci))\n",
    "                    print(len(commit))\n",
    "                    print('PROBLEM!')\n",
    "                else:\n",
    "                    print('NO PROBLEM!')\n",
    "            \n",
    "            for i in range(len(confidence)):\n",
    "                #print([p, alg, max_batch_size, confidence[i], 100*project_reqd_builds[i]/length_of_test, 100*project_missed_builds[i]/length_of_test, project_build_duration[i], 100*project_saved_builds[i]/length_of_test, project_delays[i], length_of_test, project_batch_delays[i]])\n",
    "                writer.writerow([ver, p, alg, max_batch_size, confidence[i], 100*project_reqd_builds[i]/length_of_test, 100*project_missed_builds[i]/length_of_test, 100*project_saved_builds[i]/length_of_test, project_delays[i], length_of_test, project_batch_delays[i], project_batch_medians[i], project_ci[i]])\n",
    "    result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4328079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BATCHBISECT at batch size 1 for checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "Processing checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "Processing BATCHBISECT at batch size 2 for checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "Processing checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "Processing BATCHBISECT at batch size 4 for checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "Processing checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "Processing BATCHBISECT at batch size 8 for checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "Processing checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "Processing BATCHBISECT at batch size 16 for checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "Processing checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "Processing BATCHDIVIDE4 at batch size 1 for checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "Processing checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "Processing BATCHDIVIDE4 at batch size 2 for checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "Processing checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "Processing BATCHDIVIDE4 at batch size 4 for checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "Processing checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "NO PROBLEM!\n",
      "Processing BATCHDIVIDE4 at batch size 8 for checkstyle-checkstyle/checkstyle-checkstyle.csv\n",
      "Processing checkstyle-checkstyle/checkstyle-checkstyle.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/09/2vzp5xpd2ldd4ggk4xzjt1qr0000gn/T/ipykernel_68263/658095437.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproject_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mstatic_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/09/2vzp5xpd2ldd4ggk4xzjt1qr0000gn/T/ipykernel_68263/2954912437.py\u001b[0m in \u001b[0;36mstatic_rule\u001b[0;34m(p, ver)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                                     \u001b[0mbatchdivide4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_group_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                                     \u001b[0mbatch_delays\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batch_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/09/2vzp5xpd2ldd4ggk4xzjt1qr0000gn/T/ipykernel_68263/860978135.py\u001b[0m in \u001b[0;36mbatchdivide4\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0msub_batch_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrunbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_batch_right\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mtest_number\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mbatchstop4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_batch_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrunbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_batch_left\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mtest_number\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mbatchstop4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_batch_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "for pr in project_list[-1:]:\n",
    "    for i in range(0,10):\n",
    "        static_rule(pr, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a93a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e821134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8d83e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
