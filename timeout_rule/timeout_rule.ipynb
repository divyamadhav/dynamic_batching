{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ae4ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from numpy import sqrt\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from statistics import median\n",
    "import pickle\n",
    "import csv\n",
    "import multiprocess\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2388f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list = [\n",
    "    'graylog2-server.csv',\n",
    "    'android.csv',\n",
    "    'gradle.csv',\n",
    "    'okhttp.csv',\n",
    "    'cloudify.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "347d6ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_total = 0\n",
    "MAX_BATCH = [1, 2, 4, 8, 16]\n",
    "algorithm = ['BATCHBISECT', 'BATCH4', 'BATCHSTOP4']\n",
    "confidence = list(range(2,21,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d870d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = open('all_rq2_results.csv', 'w')\n",
    "result_headers = ['version', 'project', 'algorithm', 'batch_size', 'confidence', 'project_reqd_builds', 'project_missed_builds', 'project_saved_builds', 'project_delays', 'testall_size', 'batch_delays', 'batch_median', 'ci']\n",
    "writer = csv.writer(result_file)\n",
    "writer.writerow(result_headers)\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20222440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_values(Y_data):\n",
    "    Y_t = []\n",
    "    for e in Y_data:\n",
    "        if e == 'passed':\n",
    "            Y_t.append(1)\n",
    "        else:\n",
    "            Y_t.append(0) \n",
    "    return Y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e611bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_failures(df):\n",
    "    \n",
    "    results = df['tr_status'].tolist()\n",
    "    length = len(results)\n",
    "    verdict = ['keep']\n",
    "    prev = results[0]\n",
    "    \n",
    "    for i in range(1, length):\n",
    "        if results[i] == 0:\n",
    "            if prev == 0:\n",
    "                verdict.append('discard')\n",
    "                #print(i+1)\n",
    "            else:\n",
    "                verdict.append('keep')\n",
    "        else:\n",
    "            verdict.append('keep')\n",
    "        prev = results[i]\n",
    "    \n",
    "    df['verdict'] = verdict\n",
    "    df = df[ df['verdict'] == 'keep' ]\n",
    "    df.drop('verdict', inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57728e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_get_train_test_data(file_path, first_failures=True):\n",
    "    columns = ['tr_build_id', 'git_num_all_built_commits', 'git_diff_src_churn', 'git_diff_test_churn', 'gh_diff_files_modified', 'tr_status']\n",
    "    X = pd.read_csv(file_path, usecols = columns)\n",
    "    X['tr_status'] = output_values(X['tr_status'])\n",
    "    \n",
    "    if first_failures:\n",
    "        X = get_first_failures(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ac18dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbs(project_name, ver):\n",
    "\n",
    "    project_file = \"../data/extracted_project_travis/\" + project_name + '.csv'\n",
    "    #dataset is split using first_failures\n",
    "    project =  pd_get_train_test_data(project_file, first_failures=False)\n",
    "    \n",
    "    pkl_file = 'datasets/' + project_name + '_' + str(ver) + '.pkl'\n",
    "    with open(pkl_file, 'rb') as load_file:\n",
    "        test_build_ids = pickle.load(load_file)\n",
    "    \n",
    "\n",
    "    X_train = project [ ~project['tr_build_id'].isin(test_build_ids)]\n",
    "    Y_train = X_train['tr_status'].tolist()\n",
    "    \n",
    "    X_test = project [ project['tr_build_id'].isin(test_build_ids)]\n",
    "    \n",
    "    num_feature = 4\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    param_grid = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "    grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 0)\n",
    "    \n",
    "    best_n_estimators = []\n",
    "    best_max_depth = []\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_f1_sample = 0\n",
    "    best_f1_sample_result = 0\n",
    "    best_f1_estimator = 0\n",
    "    best_thresholds = []\n",
    "    \n",
    "\n",
    "    for i in range(100):\n",
    "        print('Bootstrapping {} for {}'.format(i, project_name))\n",
    "        \n",
    "        while True:\n",
    "            print('Here for {} {}'.format(i, project_name))\n",
    "            sample_train = resample(X_train, replace=True, n_samples=len(X_train))\n",
    "            sample_train_result = sample_train['tr_status']\n",
    "\n",
    "            build_ids = sample_train['tr_build_id'].tolist()\n",
    "            sample_test = X_train [~X_train['tr_build_id'].isin(build_ids)] \n",
    "            sample_test_result = sample_test['tr_status']\n",
    "\n",
    "            if len(sample_test_result) != 0:\n",
    "                break\n",
    "        \n",
    "        sample_train.drop('tr_status', inplace=True, axis=1)\n",
    "        sample_train.drop('tr_build_id', inplace=True, axis=1)\n",
    "        sample_test.drop('tr_status', inplace=True, axis=1)\n",
    "        sample_test.drop('tr_build_id', inplace=True, axis=1)\n",
    "        \n",
    "        print('Training {} for {}'.format(i, project_name))\n",
    "        grid_search.fit(sample_train, sample_train_result)\n",
    "        sample_pred_vals = grid_search.predict_proba(sample_test)\n",
    "\n",
    "        pred_vals = sample_pred_vals[:, 1]\n",
    "        fpr, tpr, t = roc_curve(sample_test_result, pred_vals)\n",
    "        gmeans = sqrt(tpr * (1-fpr))\n",
    "        ix = argmax(gmeans)\n",
    "        bt = t[ix]\n",
    "        best_thresholds.append(bt)\n",
    "        \n",
    "        final_pred_result = []\n",
    "        #threshold setting\n",
    "        for j in range(len(pred_vals)):\n",
    "            if pred_vals[j] > bt:\n",
    "                final_pred_result.append(1)\n",
    "            else:\n",
    "                final_pred_result.append(0)\n",
    "        \n",
    "        try:\n",
    "            f1 = f1_score(sample_test_result, final_pred_result)\n",
    "        except:\n",
    "            print('')\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_f1_sample = sample_train\n",
    "            best_f1_sample_result = sample_train_result\n",
    "            best_f1_estimator = grid_search.best_estimator_\n",
    "            print(best_f1_sample)\n",
    "            \n",
    "        best_n_estimators.append(grid_search.best_params_['n_estimators'])\n",
    "        best_max_depth.append(grid_search.best_params_['max_depth'])\n",
    "        \n",
    "    #completed with bootstrapping \n",
    "    threshold = median(best_thresholds)\n",
    "    n_estimator = median(best_n_estimators)\n",
    "    max_depth = median(best_max_depth)\n",
    "\n",
    "    #retrain to get the best model\n",
    "    forest = RandomForestClassifier(n_estimators=int(n_estimator), max_depth=int(max_depth))\n",
    "    forest.fit(best_f1_sample, best_f1_sample_result)\n",
    "\n",
    "    file_name = 'trained_models/' + project_name + '_' + str(ver) + '_best_model.pkl'\n",
    "    dump_file = open(file_name, 'wb')\n",
    "    pickle.dump(forest, dump_file)\n",
    "    pickle.dump(threshold, dump_file)\n",
    "    pickle.dump(n_estimator, dump_file)\n",
    "    pickle.dump(max_depth, dump_file)\n",
    "                \n",
    "    #grid_search.fit(X_train, Y_train)\n",
    "    #return grid_search\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b486d510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_bisect(actual_group_results):\n",
    "    global batch_total\n",
    " \n",
    "    batch_total += 1\n",
    "    \n",
    "    if len(actual_group_results) == 1:\n",
    "        return\n",
    "    \n",
    "    if 0 in actual_group_results:\n",
    "        half_batch = len(actual_group_results)//2\n",
    "        batch_bisect(actual_group_results[:half_batch])\n",
    "        batch_bisect(actual_group_results[half_batch:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fec41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_stop_4(actual_group_results):\n",
    "    global batch_total\n",
    "    \n",
    "    batch_total += 1\n",
    "\n",
    "    if len(actual_group_results) <= 4:\n",
    "        if 0 in actual_group_results:\n",
    "            batch_total += 4\n",
    "        return\n",
    "    \n",
    "    if 0 in actual_group_results:\n",
    "        half_batch = len(actual_group_results)//2\n",
    "        batch_stop_4(actual_group_results[:half_batch])\n",
    "        batch_stop_4(actual_group_results[half_batch:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b511faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_rule(p, ver):\n",
    "    \n",
    "    \n",
    "    global batch_total\n",
    "    global batch_durations\n",
    "    \n",
    "    p_name = p.split('.')[0]\n",
    "    \n",
    "    result_file = open('all_rq2_results.csv', 'a+')\n",
    "    writer = csv.writer(result_file)\n",
    "\n",
    "    \n",
    "    X_test = sbs(p_name, ver)\n",
    "    if len(X_test) == 0:\n",
    "        return\n",
    "    \n",
    "    model_file_name = 'trained_models/' + p_name + '_' + str(ver) + '_best_model.pkl'\n",
    "    model_file = open(model_file_name, 'rb')\n",
    "    predictor = pickle.load(model_file)\n",
    "    threshold = pickle.load(model_file)\n",
    "    \n",
    "    Y_test = X_test['tr_status'].tolist()\n",
    "\n",
    "    X_test.drop('tr_build_id', inplace=True, axis=1)\n",
    "    X_test.drop('tr_status', inplace=True, axis=1)\n",
    "    \n",
    "    \n",
    "    for alg in algorithm:\n",
    "        for max_batch_size in MAX_BATCH:\n",
    "                        \n",
    "            if alg == 'BATCH4':\n",
    "                if max_batch_size != 4:\n",
    "                    continue\n",
    "            \n",
    "            if alg == 'BATCHSTOP4':\n",
    "                if max_batch_size < 4:\n",
    "                    continue\n",
    "                    \n",
    "            print('Processing {} at batch size {} for {}'.format(alg, max_batch_size, p))\n",
    "\n",
    "\n",
    "            Y_result = []\n",
    "            grouped_batch = []\n",
    "            actual_group_results = []\n",
    "            group_duration = []\n",
    "            num_feature = 4 \n",
    "            length_of_test = len(Y_test)\n",
    "\n",
    "            project_reqd_builds = []\n",
    "            project_missed_builds = []\n",
    "            project_build_duration = []\n",
    "            project_saved_builds = []\n",
    "            project_delays = []\n",
    "            project_bad_builds = []\n",
    "            project_batch_delays = []\n",
    "            project_batch_medians = []\n",
    "            project_ci = []\n",
    "\n",
    "            print('Processing {}'.format(p))\n",
    "            commit = predictor.predict(X_test)\n",
    "            for c in confidence:\n",
    "                ci = [Y_test[0]]\n",
    "                batch_median = []\n",
    "                batch_delays = 0\n",
    "\n",
    "                pass_streak = Y_test[0]\n",
    "                total_builds = 0\n",
    "                missed_builds = 0\n",
    "                miss_indexes = []\n",
    "                build_indexes = []\n",
    "                delay_durations = []\n",
    "\n",
    "                if pass_streak == 0:\n",
    "                    saved_builds = 0\n",
    "                else:\n",
    "                    saved_builds = 1\n",
    "\n",
    "                index = 1\n",
    "\n",
    "                while index < len(X_test):\n",
    "                    value = commit[index]\n",
    "                    #we're setting a confidence of 'c' builds on SBS, if more than 'c' passes have been suggested in a row, we don't want to trust sbs\n",
    "                    \n",
    "                    #if predict[0][1] > threshold:\n",
    "                    #    value = 1\n",
    "                    #else:\n",
    "                    #    value = 0\n",
    "                    #print('Build {} : predict_proba={}\\tprediction={}'.format(index, predict, value))\n",
    "                    \n",
    "                    \n",
    "                    if pass_streak < c :\n",
    "                        \n",
    "                        if value == 0:\n",
    "                            while True:\n",
    "\n",
    "                                grouped_batch = list(X_test[index : index+max_batch_size])\n",
    "                                actual_group_results = list(Y_test[index : index+max_batch_size])\n",
    "\n",
    "                                if alg == 'BATCH4':\n",
    "                                    if len(actual_group_results) != max_batch_size:\n",
    "                                        fb = 0\n",
    "                                        while fb < len(actual_group_results):\n",
    "                                            #miss_indexes.append(index)\n",
    "                                            batch_delays += len(actual_group_results) - fb\n",
    "                                            batch_median.append(max_batch_size-fb-1)\n",
    "                                            ci.append(0)\n",
    "                                            fb += 1\n",
    "                                            index += 1\n",
    "                                            total_builds += 1\n",
    "                                    else:\n",
    "                                        if len(miss_indexes) > 0:\n",
    "                                            if miss_indexes[-1] < index:\n",
    "                                                for l in range(len(miss_indexes)):\n",
    "                                                    e = miss_indexes.pop()\n",
    "                                                    delay_durations.append(index - e + 1)\n",
    "\n",
    "                                        batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                        batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                        ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                        total_builds += 1\n",
    "                                        \n",
    "\n",
    "                                        if 0 in actual_group_results:\n",
    "                                            total_builds += max_batch_size\n",
    "                                            \n",
    "\n",
    "                                elif alg == 'BATCHBISECT':\n",
    "                                    if len(actual_group_results) != max_batch_size:\n",
    "                                        fb = 0\n",
    "                                        while fb < len(actual_group_results):\n",
    "                                            total_builds += 1\n",
    "                                            ci.append(0)\n",
    "                                            batch_delays += len(actual_group_results) - fb\n",
    "                                            batch_median.append(max_batch_size-fb-1)\n",
    "                                            fb += 1\n",
    "                                            index += 1\n",
    "                                    else:\n",
    "                                        if len(miss_indexes) > 0:\n",
    "                                            if miss_indexes[-1] < index:\n",
    "                                                for l in range(len(miss_indexes)):\n",
    "                                                    e = miss_indexes.pop()\n",
    "                                                    delay_durations.append(index - e + 1)\n",
    "\n",
    "                                        batch_total = 0\n",
    "                                        \n",
    "                                        batch_bisect(actual_group_results)\n",
    "                                        batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                        ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                        batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                        total_builds += batch_total\n",
    "\n",
    "                                elif alg == 'BATCHSTOP4':\n",
    "                                    if len(actual_group_results) != max_batch_size:\n",
    "                                        fb = 0\n",
    "                                        while fb < len(actual_group_results):\n",
    "                                            total_builds += 1\n",
    "                                            ci.append(0)\n",
    "                                            batch_delays += len(actual_group_results) - fb\n",
    "                                            batch_median.append(max_batch_size-fb-1)\n",
    "                                            fb += 1\n",
    "                                            index += 1\n",
    "                                    else:\n",
    "                                        if len(miss_indexes) > 0:\n",
    "                                            if miss_indexes[-1] < index:\n",
    "                                                for l in range(len(miss_indexes)):\n",
    "                                                    e = miss_indexes.pop()\n",
    "                                                    delay_durations.append(index - e + 1)\n",
    "\n",
    "                                        batch_total = 0\n",
    "                                        batch_durations = 0\n",
    "\n",
    "                                        batch_stop_4(actual_group_results)\n",
    "\n",
    "                                        batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                        ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                        batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                        total_builds += batch_total\n",
    "\n",
    "\n",
    "                                if 0 in actual_group_results:\n",
    "                                    index += max_batch_size\n",
    "                                    grouped_batch.clear()\n",
    "                                    actual_group_results.clear()\n",
    "                                    \n",
    "                                else:\n",
    "                                    break\n",
    "                            index += max_batch_size\n",
    "                            pass_streak = 1\n",
    "                            grouped_batch.clear()\n",
    "                            actual_group_results.clear()\n",
    "                            \n",
    "                                \n",
    "                        else:\n",
    "                            pass_streak += 1\n",
    "                            ci.append(1)\n",
    "                            saved_builds += 1\n",
    "                            if Y_test[index] == 0:\n",
    "                                missed_builds += 1\n",
    "                                miss_indexes.append(index)\n",
    "\n",
    "                            #seeing only one build\n",
    "                            index += 1\n",
    "\n",
    "                    else:\n",
    "                        while True:\n",
    "\n",
    "                            grouped_batch = list(X_test[index : index+max_batch_size])\n",
    "                            actual_group_results = list(Y_test[index : index+max_batch_size])\n",
    "                            \n",
    "\n",
    "                            if alg == 'BATCH4':\n",
    "                                if len(actual_group_results) != max_batch_size:\n",
    "                                    fb = 0\n",
    "                                    while fb < len(actual_group_results):\n",
    "                                        total_builds += 1\n",
    "                                        ci.append(0)\n",
    "                                        batch_delays += len(actual_group_results) - fb\n",
    "                                        batch_median.append(max_batch_size-fb-1)\n",
    "                                        fb += 1\n",
    "                                        index += 1\n",
    "                                else:\n",
    "                                    if len(miss_indexes) > 0:\n",
    "                                        if miss_indexes[-1] < index:\n",
    "                                            for l in range(len(miss_indexes)):\n",
    "                                                e = miss_indexes.pop()\n",
    "                                                delay_durations.append(index - e + 1)\n",
    "                                    \n",
    "                                    batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                    ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                    batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                    total_builds += 1\n",
    "                                    \n",
    "\n",
    "                                    if 0 in actual_group_results:\n",
    "                                        total_builds += max_batch_size\n",
    "                                        \n",
    "\n",
    "                            elif alg == 'BATCHBISECT':\n",
    "                                if len(actual_group_results) != max_batch_size:\n",
    "                                    fb = 0\n",
    "                                    while fb < len(actual_group_results):\n",
    "                                        total_builds += 1\n",
    "                                        ci.append(0)\n",
    "                                        batch_delays += len(actual_group_results) - fb\n",
    "                                        batch_median.append(max_batch_size-fb-1)\n",
    "                                        fb += 1\n",
    "                                        index += 1\n",
    "                                else:\n",
    "\n",
    "                                    if len(miss_indexes) > 0:\n",
    "                                        if miss_indexes[-1] < index:\n",
    "                                            for l in range(len(miss_indexes)):\n",
    "                                                e = miss_indexes.pop()\n",
    "                                                delay_durations.append(index - e + 1)\n",
    "\n",
    "                                    batch_total = 0\n",
    "                                    \n",
    "\n",
    "                                    batch_bisect(actual_group_results)\n",
    "\n",
    "                                    batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                    batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                    \n",
    "                                    ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                    total_builds += batch_total\n",
    "\n",
    "                            elif alg == 'BATCHSTOP4':\n",
    "                                if len(actual_group_results) != max_batch_size:\n",
    "                                    fb = 0\n",
    "                                    while fb < len(actual_group_results):\n",
    "                                        total_builds += 1\n",
    "                                        ci.append(0)\n",
    "                                        batch_delays += len(actual_group_results) - fb\n",
    "                                        batch_median.append(max_batch_size-fb-1)\n",
    "                                        fb += 1\n",
    "                                        index += 1\n",
    "                                else:\n",
    "\n",
    "                                    if len(miss_indexes) > 0:\n",
    "                                        if miss_indexes[-1] < index:\n",
    "                                            for l in range(len(miss_indexes)):\n",
    "                                                e = miss_indexes.pop()\n",
    "                                                delay_durations.append(index - e + 1)\n",
    "\n",
    "                                    batch_total = 0\n",
    "                                    \n",
    "\n",
    "                                    batch_stop_4(actual_group_results)\n",
    "\n",
    "                                    batch_delays += max_batch_size*(max_batch_size-1)/2\n",
    "                                    batch_median.extend([max_batch_size-clb-1 for clb in range(max_batch_size)])\n",
    "                                    ci.extend([0 for clb in range(max_batch_size)])\n",
    "                                    total_builds += batch_total\n",
    "                                    \n",
    "                            if 0 in actual_group_results:\n",
    "                                index += max_batch_size\n",
    "                                grouped_batch.clear()\n",
    "                                actual_group_results.clear()\n",
    "                                \n",
    "                            else:\n",
    "                                break\n",
    "                        index += max_batch_size\n",
    "                        pass_streak = 1\n",
    "                        grouped_batch.clear()\n",
    "                        actual_group_results.clear()\n",
    "                        \n",
    "                mi = 0\n",
    "                while len(miss_indexes) > 0:\n",
    "                        m_index = miss_indexes.pop()\n",
    "                        delay_durations.append(length_of_test - m_index + 1)\n",
    "\n",
    "                project_reqd_builds.append(total_builds)\n",
    "                project_missed_builds.append(missed_builds)\n",
    "                project_saved_builds.append(saved_builds)\n",
    "                project_delays.append(delay_durations)\n",
    "                project_batch_delays.append(batch_delays)\n",
    "                project_batch_medians.append(batch_median)\n",
    "                project_ci.append(ci)\n",
    "                \n",
    "                if len(ci) != len(commit):\n",
    "                    print(len(ci))\n",
    "                    print(len(commit))\n",
    "                    print('PROBLEM!')\n",
    "                else:\n",
    "                    print('NO PROBLEM!')\n",
    "            \n",
    "            for i in range(len(confidence)):\n",
    "                #print([p, alg, max_batch_size, confidence[i], 100*project_reqd_builds[i]/length_of_test, 100*project_missed_builds[i]/length_of_test, project_build_duration[i], 100*project_saved_builds[i]/length_of_test, project_delays[i], length_of_test, project_batch_delays[i]])\n",
    "                writer.writerow([ver, p, alg, max_batch_size, confidence[i], 100*project_reqd_builds[i]/length_of_test, 100*project_missed_builds[i]/length_of_test, 100*project_saved_builds[i]/length_of_test, project_delays[i], length_of_test, project_batch_delays[i], project_batch_medians[i], project_ci[i]])\n",
    "    result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52bd9bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4680 519\n",
      "4680 519\n",
      "4680 519\n",
      "4680 519\n",
      "4680 519\n",
      "4680 519\n",
      "4680 519\n",
      "4680 519\n",
      "4680 519\n",
      "4671 528\n",
      "4007 445\n",
      "4007 445\n",
      "4007 445\n",
      "4007 445\n",
      "4007 445\n",
      "4007 445\n",
      "4007 445\n",
      "4007 445\n",
      "4007 445\n",
      "4005 447\n",
      "3618 401\n",
      "3618 401\n",
      "3618 401\n",
      "3618 401\n",
      "3618 401\n",
      "3618 401\n",
      "3618 401\n",
      "3618 401\n",
      "3618 401\n",
      "3609 410\n",
      "3254 361\n",
      "3254 361\n",
      "3254 361\n",
      "3254 361\n",
      "3254 361\n",
      "3254 361\n",
      "3254 361\n",
      "3254 361\n",
      "3254 361\n",
      "3249 366\n",
      "5168 574\n",
      "5168 574\n",
      "5168 574\n",
      "5168 574\n",
      "5168 574\n",
      "5168 574\n",
      "5168 574\n",
      "5168 574\n",
      "5168 574\n",
      "5166 576\n"
     ]
    }
   ],
   "source": [
    "for pr in project_list:\n",
    "    for i in range(0,10):\n",
    "        static_rule(pr, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37705c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
